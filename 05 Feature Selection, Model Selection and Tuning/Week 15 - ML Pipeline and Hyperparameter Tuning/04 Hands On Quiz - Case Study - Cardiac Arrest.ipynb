{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9872e15",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "df86fa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 226;\n",
       "                var nbb_unformatted_code = \"# Libraries to help with reading and manipulating data\\nimport numpy as np\\nimport pandas as pd\\n\\n# Libraries to help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# To tune model, get different metric scores and split data\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\\nfrom sklearn.metrics import (\\n    f1_score,\\n    accuracy_score,\\n    recall_score,\\n    precision_score,\\n    confusion_matrix,\\n    roc_auc_score,\\n    plot_confusion_matrix,\\n    classification_report,\\n    make_scorer,\\n)\\n\\nfrom sklearn.tree import DecisionTreeClassifier\\n\\n# To build a logistic regression model\\nfrom sklearn.linear_model import LogisticRegression\\n\\n# To oversample and undersample data\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.under_sampling import RandomUnderSampler\\n\\n# To suppress the warnings\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# This will help in making the Python code more structured automatically (good coding practice)\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"# Libraries to help with reading and manipulating data\\nimport numpy as np\\nimport pandas as pd\\n\\n# Libraries to help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# To tune model, get different metric scores and split data\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\\nfrom sklearn.metrics import (\\n    f1_score,\\n    accuracy_score,\\n    recall_score,\\n    precision_score,\\n    confusion_matrix,\\n    roc_auc_score,\\n    plot_confusion_matrix,\\n    classification_report,\\n    make_scorer,\\n)\\n\\nfrom sklearn.tree import DecisionTreeClassifier\\n\\n# To build a logistic regression model\\nfrom sklearn.linear_model import LogisticRegression\\n\\n# To oversample and undersample data\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.under_sampling import RandomUnderSampler\\n\\n# To suppress the warnings\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# This will help in making the Python code more structured automatically (good coding practice)\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Libraries to help with reading and manipulating data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Libraries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To tune model, get different metric scores and split data\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    plot_confusion_matrix,\n",
    "    classification_report,\n",
    "    make_scorer,\n",
    ")\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# To build a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# To oversample and undersample data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# To suppress the warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# This will help in making the Python code more structured automatically (good coding practice)\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155ee141",
   "metadata": {},
   "source": [
    "**1. Load the cardiac dataset. Identify the correct percentage of the positive (Yes) and negative (No) class distribution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "bf4aa387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     0.786277\n",
       "yes    0.213723\n",
       "Name: UnderRisk, dtype: float64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 227;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\n\\ncardiac = pd.read_csv(\\\"./datasets/Cardiac.csv\\\")\\ndf = cardiac.copy()\\ndf[\\\"UnderRisk\\\"].value_counts(normalize=True)\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\n\\ncardiac = pd.read_csv(\\\"./datasets/Cardiac.csv\\\")\\ndf = cardiac.copy()\\ndf[\\\"UnderRisk\\\"].value_counts(normalize=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cardiac = pd.read_csv(\"./datasets/Cardiac.csv\")\n",
    "df = cardiac.copy()\n",
    "df[\"UnderRisk\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1bf898",
   "metadata": {},
   "source": [
    "**2. Prepare the data according to the following instructions in a sequential manner.**\n",
    "1. Encode target variable (Replace yes with 1 and no with 0)\n",
    "2. Split the data into temp and test in the 80:20 ratio. Use the parameter ‘stratify’ while splitting the data\n",
    "3. Split the temp set into train and validation in the 75:25 ratio. Use the parameter ‘stratify’ while splitting the data\n",
    "4. Create dummies for X_train, X_val, and X_test. Use drop_first = True while creating dummies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "5b548cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is (889, 12)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 228;\n",
       "                var nbb_unformatted_code = \"# split into X and Y\\nX = df.drop([\\\"UnderRisk\\\"], axis=1)\\ny = df.UnderRisk\\nprint(\\\"The shape of X is\\\", X.shape)\";\n",
       "                var nbb_formatted_code = \"# split into X and Y\\nX = df.drop([\\\"UnderRisk\\\"], axis=1)\\ny = df.UnderRisk\\nprint(\\\"The shape of X is\\\", X.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split into X and Y\n",
    "X = df.drop([\"UnderRisk\"], axis=1)\n",
    "y = df.UnderRisk\n",
    "print(\"The shape of X is\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f7ced57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 229;\n",
       "                var nbb_unformatted_code = \"# y.apply(lambda x: 1 if x == \\\"yes\\\" else 0)\\n\\nfrom sklearn.preprocessing import LabelEncoder\\nle = LabelEncoder()\\ny = le.fit_transform(y)\\nle.transform([\\\"yes\\\", \\\"no\\\"])\";\n",
       "                var nbb_formatted_code = \"# y.apply(lambda x: 1 if x == \\\"yes\\\" else 0)\\n\\nfrom sklearn.preprocessing import LabelEncoder\\n\\nle = LabelEncoder()\\ny = le.fit_transform(y)\\nle.transform([\\\"yes\\\", \\\"no\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y.apply(lambda x: 1 if x == \"yes\" else 0)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "le.transform([\"yes\", \"no\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "6c2d4f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 230;\n",
       "                var nbb_unformatted_code = \"# Splitting data into training, validation and test set:\\n# first we split data into 2 parts, say temporary and test\\n\\nX_temp, X_test, y_temp, y_test = train_test_split(\\n    X, y, test_size=0.2, random_state=1, stratify=y\\n)\";\n",
       "                var nbb_formatted_code = \"# Splitting data into training, validation and test set:\\n# first we split data into 2 parts, say temporary and test\\n\\nX_temp, X_test, y_temp, y_test = train_test_split(\\n    X, y, test_size=0.2, random_state=1, stratify=y\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Splitting data into training, validation and test set:\n",
    "# first we split data into 2 parts, say temporary and test\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8e11c1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(533, 12) (178, 12) (178, 12)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 231;\n",
       "                var nbb_unformatted_code = \"# then we split the temporary set into train and validation\\n\\nX_train, X_val, y_train, y_val = train_test_split(\\n    X_temp, y_temp, test_size=0.25, random_state=1, stratify=y_temp\\n)\\nprint(X_train.shape, X_val.shape, X_test.shape)\";\n",
       "                var nbb_formatted_code = \"# then we split the temporary set into train and validation\\n\\nX_train, X_val, y_train, y_val = train_test_split(\\n    X_temp, y_temp, test_size=0.25, random_state=1, stratify=y_temp\\n)\\nprint(X_train.shape, X_val.shape, X_test.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# then we split the temporary set into train and validation\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=1, stratify=y_temp\n",
    ")\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "d8af82bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(533, 13) (178, 13) (178, 13)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 232;\n",
       "                var nbb_unformatted_code = \"# Creating Dummy Variables\\n\\nX_train = pd.get_dummies(X_train, drop_first=True)\\nX_val = pd.get_dummies(X_val, drop_first=True)\\nX_test = pd.get_dummies(X_test, drop_first=True)\\nprint(X_train.shape, X_val.shape, X_test.shape)\";\n",
       "                var nbb_formatted_code = \"# Creating Dummy Variables\\n\\nX_train = pd.get_dummies(X_train, drop_first=True)\\nX_val = pd.get_dummies(X_val, drop_first=True)\\nX_test = pd.get_dummies(X_test, drop_first=True)\\nprint(X_train.shape, X_val.shape, X_test.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating Dummy Variables\n",
    "\n",
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_val = pd.get_dummies(X_val, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34fc6e4",
   "metadata": {},
   "source": [
    "**3. Here, we are attempting to predict whether a person will have cardiac arrest or not based on his medical background. According to you, which of the following would be the most appropriate metric of evaluation for prediction.**\n",
    "\n",
    "Ans: Recall\n",
    "\n",
    "In medical cases, predicting the presence of disease in the patients who actually have a disease is more important than predicting the absence of the disease in the patients who do not have the disease.  In such cases, reducing the number of FP is more important than FN. Therefore, the right metric would be recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5452f3e3",
   "metadata": {},
   "source": [
    "**4. Now that we have decided on our evaluation metric, we can go ahead to build models. Since cardiac arrest prediction is a classification problem, we can start with logistic regression.**\n",
    "\n",
    "Train the models as per the following instructions.\n",
    "\n",
    "Build a logistic regression on the train set using the sklearn implementation with default parameters and random_state=1 and check the performance of the model on the train set. \n",
    "Oversample the train set using SMOTE with parameters listed below, build a logistic regression on the oversampled data, and check the performance of the model on the oversampled train set.\n",
    "SMOTE parameters: sampling_strategy=1, k_neighbors=5, random_state=1\n",
    "\n",
    "Which of the following statements is true on comparing the performance of both the models on train data and oversampled train data.\n",
    "\n",
    "Ans: Accuracy of the model on an oversampled set has decreased whereas recall and precision of the oversampled data have increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "41846a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 233;\n",
       "                var nbb_unformatted_code = \"# defining a function to compute different metrics to check performance of a classification model built using sklearn\\ndef model_performance_classification_sklearn(model, predictors, target):\\n    \\\"\\\"\\\"\\n    Function to compute different metrics to check classification model performance\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n\\n    # predicting using the independent variables\\n    pred = model.predict(predictors)\\n\\n    acc = accuracy_score(target, pred)  # to compute Accuracy\\n    recall = recall_score(target, pred)  # to compute Recall\\n    precision = precision_score(target, pred)  # to compute Precision\\n    f1 = f1_score(target, pred)  # to compute F1-score\\n\\n    # creating a dataframe of metrics\\n    df_perf = pd.DataFrame(\\n        {\\\"Accuracy\\\": acc, \\\"Recall\\\": recall, \\\"Precision\\\": precision, \\\"F1\\\": f1,},\\n        index=[0],\\n    )\\n\\n    return df_perf\";\n",
       "                var nbb_formatted_code = \"# defining a function to compute different metrics to check performance of a classification model built using sklearn\\ndef model_performance_classification_sklearn(model, predictors, target):\\n    \\\"\\\"\\\"\\n    Function to compute different metrics to check classification model performance\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n\\n    # predicting using the independent variables\\n    pred = model.predict(predictors)\\n\\n    acc = accuracy_score(target, pred)  # to compute Accuracy\\n    recall = recall_score(target, pred)  # to compute Recall\\n    precision = precision_score(target, pred)  # to compute Precision\\n    f1 = f1_score(target, pred)  # to compute F1-score\\n\\n    # creating a dataframe of metrics\\n    df_perf = pd.DataFrame(\\n        {\\\"Accuracy\\\": acc, \\\"Recall\\\": recall, \\\"Precision\\\": precision, \\\"F1\\\": f1,},\\n        index=[0],\\n    )\\n\\n    return df_perf\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining a function to compute different metrics to check performance of a classification model built using sklearn\n",
    "def model_performance_classification_sklearn(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute different metrics to check classification model performance\n",
    "\n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "\n",
    "    # predicting using the independent variables\n",
    "    pred = model.predict(predictors)\n",
    "\n",
    "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
    "    recall = recall_score(target, pred)  # to compute Recall\n",
    "    precision = precision_score(target, pred)  # to compute Precision\n",
    "    f1 = f1_score(target, pred)  # to compute F1-score\n",
    "\n",
    "    # creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\"Accuracy\": acc, \"Recall\": recall, \"Precision\": precision, \"F1\": f1,},\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "dde3282b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 234;\n",
       "                var nbb_unformatted_code = \"def confusion_matrix_sklearn(model, predictors, target):\\n    \\\"\\\"\\\"\\n    To plot the confusion_matrix with percentages\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n    y_pred = model.predict(predictors)\\n    cm = confusion_matrix(target, y_pred)\\n    labels = np.asarray(\\n        [\\n            [\\\"{0:0.0f}\\\".format(item) + \\\"\\\\n{0:.2%}\\\".format(item / cm.flatten().sum())]\\n            for item in cm.flatten()\\n        ]\\n    ).reshape(2, 2)\\n\\n    plt.figure(figsize=(6, 4))\\n    sns.heatmap(cm, annot=labels, fmt=\\\"\\\")\\n    plt.ylabel(\\\"True label\\\")\\n    plt.xlabel(\\\"Predicted label\\\")\";\n",
       "                var nbb_formatted_code = \"def confusion_matrix_sklearn(model, predictors, target):\\n    \\\"\\\"\\\"\\n    To plot the confusion_matrix with percentages\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n    y_pred = model.predict(predictors)\\n    cm = confusion_matrix(target, y_pred)\\n    labels = np.asarray(\\n        [\\n            [\\\"{0:0.0f}\\\".format(item) + \\\"\\\\n{0:.2%}\\\".format(item / cm.flatten().sum())]\\n            for item in cm.flatten()\\n        ]\\n    ).reshape(2, 2)\\n\\n    plt.figure(figsize=(6, 4))\\n    sns.heatmap(cm, annot=labels, fmt=\\\"\\\")\\n    plt.ylabel(\\\"True label\\\")\\n    plt.xlabel(\\\"Predicted label\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def confusion_matrix_sklearn(model, predictors, target):\n",
    "    \"\"\"\n",
    "    To plot the confusion_matrix with percentages\n",
    "\n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(predictors)\n",
    "    cm = confusion_matrix(target, y_pred)\n",
    "    labels = np.asarray(\n",
    "        [\n",
    "            [\"{0:0.0f}\".format(item) + \"\\n{0:.2%}\".format(item / cm.flatten().sum())]\n",
    "            for item in cm.flatten()\n",
    "        ]\n",
    "    ).reshape(2, 2)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=labels, fmt=\"\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "dd78a6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.787992</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.066116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy    Recall  Precision        F1\n",
       "0  0.787992  0.035088   0.571429  0.066116"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 235;\n",
       "                var nbb_unformatted_code = \"from sklearn.linear_model import LogisticRegression\\n\\n# Fit the model on original data i.e. before upsampling\\nlr = LogisticRegression(random_state=1)\\nlr.fit(X_train, y_train)\\n\\n# Calculating different metrics on train set\\nlog_reg_model_train_perf = model_performance_classification_sklearn(\\n    lr, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\")\\nlog_reg_model_train_perf\";\n",
       "                var nbb_formatted_code = \"from sklearn.linear_model import LogisticRegression\\n\\n# Fit the model on original data i.e. before upsampling\\nlr = LogisticRegression(random_state=1)\\nlr.fit(X_train, y_train)\\n\\n# Calculating different metrics on train set\\nlog_reg_model_train_perf = model_performance_classification_sklearn(\\n    lr, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\")\\nlog_reg_model_train_perf\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fit the model on original data i.e. before upsampling\n",
    "lr = LogisticRegression(random_state=1)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Calculating different metrics on train set\n",
    "log_reg_model_train_perf = model_performance_classification_sklearn(\n",
    "    lr, X_train, y_train\n",
    ")\n",
    "print(\"Training performance:\")\n",
    "log_reg_model_train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e7a77153",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This AdaBoostClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-236-cf7ffee3b18a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfusion_matrix_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-234-6cba3ec5bef5>\u001b[0m in \u001b[0;36mconfusion_matrix_sklearn\u001b[0;34m(model, predictors, target)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdependent\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     labels = np.asarray(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;32mclass\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrespectively\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \"\"\"\n\u001b[0;32m--> 694\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This AdaBoostClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 236;\n",
       "                var nbb_unformatted_code = \"confusion_matrix_sklearn(model, X_val, y_val)\";\n",
       "                var nbb_formatted_code = \"confusion_matrix_sklearn(model, X_val, y_val)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_sklearn(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4704d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE to upsample smaller class\n",
    "\n",
    "print(\"Before UpSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
    "print(\"Before UpSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
    "\n",
    "sm = SMOTE(\n",
    "    sampling_strategy=1, k_neighbors=5, random_state=1\n",
    ")  # Synthetic Minority Over Sampling Technique\n",
    "X_train_over, y_train_over = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After UpSampling, counts of label '1': {}\".format(sum(y_train_over == 1)))\n",
    "print(\"After UpSampling, counts of label '0': {} \\n\".format(sum(y_train_over == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a64f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on upsampled data\n",
    "log_reg_over = LogisticRegression(random_state=1)\n",
    "\n",
    "# Training the basic logistic regression model with training set\n",
    "log_reg_over.fit(X_train_over, y_train_over)\n",
    "\n",
    "# Calculating different metrics on train set\n",
    "log_reg_over_train_perf = model_performance_classification_sklearn(\n",
    "    log_reg_over, X_train_over, y_train_over\n",
    ")\n",
    "print(\"Training performance:\")\n",
    "log_reg_over_train_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4f5b24",
   "metadata": {},
   "source": [
    "**5. Let's try some other algorithms before settling on a final model.**\n",
    "\n",
    "Train a bagging classifier on the oversampled data using the sklearn implementation with default parameters and random_state=1 and check the model performance on the validation set.\n",
    "Which of the following options gives the correct range of the evaluation metrics?\n",
    "\n",
    "Ans:\n",
    "Recall: In a range of 0.55 to 0.65 \n",
    "Precision: In a range of 0.20 to 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50987197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging Classifier - base_estimator for bagging classifier is a decision tree by default\n",
    "bagging_estimator_over = BaggingClassifier(random_state=1)\n",
    "bagging_estimator_over.fit(X_train_over, y_train_over)\n",
    "\n",
    "# Calculating different metrics on validation set\n",
    "bag_over_val_perf = model_performance_classification_sklearn(\n",
    "    bagging_estimator_over, X_val, y_val\n",
    ")\n",
    "print(\"validation performance:\")\n",
    "bag_over_val_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d068c0e0",
   "metadata": {},
   "source": [
    "**6. Let’s try one more model and see how our model performs. Along with the evaluation metrics, we should check how many observations are correctly predicted by our model.**\n",
    "\n",
    "Train a random forest classifier with the original training set  using the sklearn implementation with default parameters and random_state=1 and assess the model performance on the training set. \n",
    "\n",
    "Identify the correct range of number of cases that are correctly predicted as ‘yes’ by the random forest classifier:\n",
    "\n",
    "Ans: 15 to 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b88fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the random forest classifier\n",
    "rf_estimator = RandomForestClassifier(random_state=1)\n",
    "rf_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62325622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating different metrics on train set\n",
    "rf_estimator_train_perf = model_performance_classification_sklearn(\n",
    "    rf_estimator, X_train, y_train\n",
    ")\n",
    "print(\"Training performance:\")\n",
    "rf_estimator_train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2fc72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating confusion matrix\n",
    "confusion_matrix_sklearn(rf_estimator, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d047d",
   "metadata": {},
   "source": [
    "**7. One model might not give the desired outcome, we can try different models and compare their performances. Let’s try different models.**\n",
    "\n",
    "Train the models as per the following instructions. \n",
    "- Train Bagging classifier using BaggingClassifier(random_state=1)\n",
    "- Train Random forest classifier using RandomForestClassifier(random_state=1)\n",
    "- Train Logistic regression using LogisticRegression(random_state=1)\n",
    "- Train Decision trees using  DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "Loop through all the above models to get the mean cross-validated scores. Use the following code for the CV results on **over sampled data** - \n",
    "```\n",
    "    scoring = \"recall\"\n",
    "    kfold = StratifiedKFold(\n",
    "\n",
    "        n_splits=5, shuffle=True, random_state=1\n",
    "\n",
    "    )  # Setting number of splits equal to 5\n",
    "\n",
    "    cv_result = cross_val_score(\n",
    "\n",
    "        estimator=model, X=X_train_over, y=y_train_over, scoring=scoring, cv=kfold\n",
    "\n",
    "    )\n",
    "```\n",
    "Which of the following statements are true about the cross-validated recall scores on the oversampled data? \n",
    "- A. The average cross-validated recall score for the bagging classifier and the random forest is approximately the same. \n",
    "- B. The difference between the CV recall scores for logistic regression and decision tree is in the range of 1-5. \n",
    "- C. The CV recall score for logistic regression lies in the range of 0.75 to 0.90\n",
    "- D. The CV recall score for decision trees lies in the range of 0.75 to 0.90\n",
    "\n",
    "Ans: A, C, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ede3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "models = []  # Empty list to store all the models\n",
    "\n",
    "# Appending models into the list\n",
    "models.append((\"Bagging\", BaggingClassifier(random_state=1)))\n",
    "models.append((\"Random forest\", RandomForestClassifier(random_state=1)))\n",
    "models.append((\"LR\", LogisticRegression(random_state=1)))\n",
    "models.append((\"dtree\", DecisionTreeClassifier(random_state=1)))\n",
    "\n",
    "results = []  # Empty list to store all model's CV scores\n",
    "names = []  # Empty list to store name of the models\n",
    "\n",
    "# loop through all models to get the mean cross validated score\n",
    "print(\"\\n\" \"Cross-Validation Performance:\" \"\\n\")\n",
    "for name, model in models:\n",
    "    scoring = \"recall\"\n",
    "\n",
    "    kfold = StratifiedKFold(\n",
    "        n_splits=5, shuffle=True, random_state=1\n",
    "    )  # Setting number of splits equal to 5\n",
    "\n",
    "    cv_result = cross_val_score(\n",
    "        estimator=model, X=X_train_over, y=y_train_over, scoring=scoring, cv=kfold\n",
    "    )\n",
    "\n",
    "    results.append(cv_result)\n",
    "\n",
    "    names.append(name)\n",
    "\n",
    "    print(\"{}: {}\".format(name, cv_result.mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81736cf",
   "metadata": {},
   "source": [
    "**8. Building the model with default parameters might not give a satisfactory outcome. Let’s try to identify the best combination of the hyperparameters.**\n",
    "\n",
    "Train an AdaBoost classifier using the oversampled data and tune the model using random search. \n",
    "\n",
    "Use the following code to define the parameters - \n",
    "\n",
    "```\n",
    "param_grid = {\n",
    "\n",
    "    \"n_estimators\": np.arange(10, 110, 10),\n",
    "\n",
    "    \"learning_rate\": [0.1, 0.01, 0.2, 0.05, 1],\n",
    "\n",
    "    \"base_estimator\": [\n",
    "\n",
    "        DecisionTreeClassifier(max_depth=1, random_state=1),\n",
    "\n",
    "        DecisionTreeClassifier(max_depth=2, random_state=1),\n",
    "\n",
    "        DecisionTreeClassifier(max_depth=3, random_state=1),\n",
    "\n",
    "    ],\n",
    "\n",
    "}\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "\n",
    "scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "\n",
    "    estimator=model,\n",
    "\n",
    "    param_distributions=param_grid,\n",
    "\n",
    "    n_jobs=-1,\n",
    "\n",
    "    n_iter=50,\n",
    "\n",
    "    scoring=scorer,\n",
    "\n",
    "    cv=5,\n",
    "\n",
    "    random_state=1,\n",
    "\n",
    ")\n",
    "```\n",
    "Which of the following is the best combination of the hyperparameters obtained on tuning the Adaboost classifier with oversampled data?\n",
    "\n",
    "Ans: Best combination of the parameters are {'n_estimators': 50, 'learning_rate': 0.01, 'base_estimator': DecisionTreeClassifier(max_depth=1, random_state=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bcf9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model = AdaBoostClassifier(random_state=1)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": np.arange(10, 110, 10),\n",
    "    \"learning_rate\": [0.1, 0.01, 0.2, 0.05, 1],\n",
    "    \"base_estimator\": [\n",
    "        DecisionTreeClassifier(max_depth=1, random_state=1),\n",
    "        DecisionTreeClassifier(max_depth=2, random_state=1),\n",
    "        DecisionTreeClassifier(max_depth=3, random_state=1),\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = make_scorer(recall_score)\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    n_jobs=-1,\n",
    "    n_iter=50,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "randomized_cv.fit(X_train_over, y_train_over)\n",
    "print(randomized_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd97fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(randomized_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac7e67",
   "metadata": {},
   "source": [
    "**9. We can further check how our model performs on oversampled and undersampled data.**\n",
    "\n",
    "Train the Adaboost classifier with undersampled and oversampled data. Assess the model performance for Adaboost with oversampled data on the oversampled train data and for Adaboost with undersampled data on the undersampled train data. \n",
    "\n",
    "Which of the following statements is true about the performance of the model? \n",
    "\n",
    "Ans: The performance of the model trained with undersampled data is better than the performance of the model trained with oversampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bac6202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=1)\n",
    "X_train_un, y_train_un = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "ada_under = AdaBoostClassifier(random_state=1)\n",
    "ada_under.fit(X_train_un, y_train_un)\n",
    "model_performance_classification_sklearn(ada_under, X_train_un, y_train_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5fd2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_over = AdaBoostClassifier(random_state=1)\n",
    "ada_over.fit(X_train_over, y_train_over)\n",
    "model_performance_classification_sklearn(ada_over, X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a2b81",
   "metadata": {},
   "source": [
    "**10. It is important to understand the features that are critical in making the right predictions. Let’s try out what are the important features for our model.** \n",
    "\n",
    "Plot the feature importance of the variables for the Adaboost classifier trained with undersampled data. \n",
    "\n",
    "Which of the following are the most important features?\n",
    "\n",
    "Ans: Gender and HighBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8705090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model1 = AdaBoostClassifier(random_state=1)\n",
    "model1.fit(X_train_un, y_train_un)\n",
    "\n",
    "feature_names = X_train_un.columns\n",
    "importances = model1.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c91661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
